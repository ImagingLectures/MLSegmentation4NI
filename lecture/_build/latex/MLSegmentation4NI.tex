%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}




\title{Segmenting neutron images using machine learning}
\date{Jan 06, 2021}
\release{}
\author{Anders Kaestner}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{ML4NeutronImageSegmentation::doc}}





\chapter{Lecture outline}
\label{\detokenize{ML4NeutronImageSegmentation:lecture-outline}}
In this lecture about machine learning to segment neutron images we will cover the following topics
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Introduction

\item {} 
Limited data problem

\item {} 
Unsupervised segmentation

\item {} 
Supervised segmentation

\item {} 
Final problem: Segmenting root networks using convolutional NNs

\item {} 
Future Machine learning challenges in NI

\end{enumerate}


\section{Importing needed modules}
\label{\detokenize{ML4NeutronImageSegmentation:importing-needed-modules}}
This lecture needs some modules to run. We import all of them here.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\PYG{k+kn}{import} \PYG{n+nn}{skimage}\PYG{n+nn}{.}\PYG{n+nn}{filters} \PYG{k}{as} \PYG{n+nn}{flt}

\PYG{k+kn}{from} \PYG{n+nn}{IPython}\PYG{n+nn}{.}\PYG{n+nn}{display} \PYG{k+kn}{import} \PYG{n}{set\PYGZus{}matplotlib\PYGZus{}formats}
\PYG{n}{set\PYGZus{}matplotlib\PYGZus{}formats}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{svg}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{png}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib} \PYG{k}{as} \PYG{n+nn}{mpl}
\PYG{n}{mpl}\PYG{o}{.}\PYG{n}{rcParams}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{figure.dpi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{l+m+mi}{150}
\end{sphinxVerbatim}


\chapter{Introduction}
\label{\detokenize{ML4NeutronImageSegmentation:introduction}}\begin{itemize}
\item {} 
Introduction to neutron imaging
\begin{itemize}
\item {} 
Some words about the method

\item {} 
Contrasts

\end{itemize}

\item {} 
Introduction to segmentation
\begin{itemize}
\item {} 
What is segmentation

\item {} 
Noise and SNR

\end{itemize}

\item {} 
Problematic segmentation tasks
\begin{itemize}
\item {} 
Intro

\item {} 
Segmenation problems in neutron imaging

\end{itemize}

\end{itemize}


\section{What is an image?}
\label{\detokenize{ML4NeutronImageSegmentation:what-is-an-image}}

\bigskip\hrule\bigskip


A very abstract definition:
\begin{itemize}
\item {} 
\sphinxstylestrong{A pairing between spatial information (position)}

\item {} 
\sphinxstylestrong{and some other kind of information (value).}

\end{itemize}

In most cases this is a two\sphinxhyphen{} or three\sphinxhyphen{}dimensional position (x,y,z coordinates) and a numeric value (intensity)


\section{Science and Imaging}
\label{\detokenize{ML4NeutronImageSegmentation:science-and-imaging}}
Images are great for qualitative analyses since our brains can quickly interpret them without large \sphinxstyleemphasis{programming} investements.


\subsection{Proper processing and quantitative analysis is however much more difficult with images.}
\label{\detokenize{ML4NeutronImageSegmentation:proper-processing-and-quantitative-analysis-is-however-much-more-difficult-with-images}}\begin{itemize}
\item {} 
If you measure a temperature, quantitative analysis is easy, \(50K\).

\item {} 
If you measure an image it is much more difficult and much more prone to mistakes, subtle setup variations, and confusing analyses

\end{itemize}


\subsection{Furthermore in image processing there is a plethora of tools available}
\label{\detokenize{ML4NeutronImageSegmentation:furthermore-in-image-processing-there-is-a-plethora-of-tools-available}}\begin{itemize}
\item {} 
Thousands of algorithms available

\item {} 
Thousands of tools

\item {} 
Many images require multi\sphinxhyphen{}step processing

\item {} 
Experimenting is time\sphinxhyphen{}consuming

\end{itemize}


\section{Some word about neutron imaging}
\label{\detokenize{ML4NeutronImageSegmentation:some-word-about-neutron-imaging}}
Neutron imaging is a method based on transmission of the neutron radiation through a sample, i.e. the fundamental information is a radiograph. In this sense it is very much similar to the more known x\sphinxhyphen{}ray imaging. The intensity in a radiographic image proportional to the amount of radiation that remains after it was transmitted through the sample. The transmitted radiation is described by Beer\sphinxhyphen{}Lambert’s law which in its basic form look like

\(I=I_0\cdot{}e^{-\int_L \mu{}(x) dx}\)

Where \(\mu(x)\) is the attenuation coefficient of the sample at position \sphinxstyleemphasis{x}.

Single radiographs are relatively rare. In most experiments the radiographs are part of a time series aquisition or projections for the 3D tomography reconstuction. In this lecture we are not going very much into the details about the imaging method as such. This is a topic for other schools that are offered.


\section{Neutron imaging contrast}
\label{\detokenize{ML4NeutronImageSegmentation:neutron-imaging-contrast}}

\section{Measurements are rarely perfect}
\label{\detokenize{ML4NeutronImageSegmentation:measurements-are-rarely-perfect}}


There is no perfect measurement. This is also true for neutron imaging. The ideal image is the sample is distorted for many reasons. The figure below shows how an image of a sample can look after passing though the acquisition system. These quailty degradations will have an impact on the analysis of the image data. In some cases, it is possible to correct for some of these artifacts using classing image processing techniques. There are however also cases that require extra effort to correct the artifacts.\sphinxincludegraphics{{imperfect_imaging_system}.pdf}


\subsection{Factors affecting the image quality}
\label{\detokenize{ML4NeutronImageSegmentation:factors-affecting-the-image-quality}}
The list below provides some factors that affect the quality of the acquired images. Most of them can be handled by changing the imaging configuration in some sense. It can however be that the sample or process observed put limitiations on how much the acquisition can be tuned to obtain the perfect image.
\begin{itemize}
\item {} 
Resolution (Imaging system transfer functions)

\item {} 
Noise

\item {} 
Contrast

\item {} 
Inhomogeneous contrast

\item {} 
Artifacts

\end{itemize}


\subsubsection{Resolution}
\label{\detokenize{ML4NeutronImageSegmentation:resolution}}
The resolution is primarily determined optical transfer function of the imaging system. The actual resolution is given by the extents of the sample and how much the detector needs to capture in one image. This gives the field of view and given the number pixels in the used detector it is possible to calculate the pixel size. The pixel size limits the size of the smallest feature in the image that can be detected. The scintillator, which is used to convert neutrons into visible light, is chosen to
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
match the sampling rate given by the pixel size.

\item {} 
provide sufficient neutron capture to obtain sufficient light output for a given exposure time.

\end{enumerate}


\subsubsection{Noise}
\label{\detokenize{ML4NeutronImageSegmentation:noise}}
An imaging system has many noise sources, each with its own distribution e.g.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Neutron statistics \sphinxhyphen{} how many neutrons are collected in a pixel. This noise is Poisson distributed.

\item {} 
Photon statistics \sphinxhyphen{} how many photons are produced by each neutron. This noise is also Poisson distributed.

\item {} 
Thermal noise from the electronics which has a Gaussian distribution.

\item {} 
Digitation noise from converting the charges collected for the photons into digital numbers that can be transfered and stored by a computer, this noise has a binominal distribution.

\end{enumerate}

The neutron statistics are mostly dominant in neutron imaging but in some cases it could also be that the photon statistics play a role.


\subsubsection{Contrast}
\label{\detokenize{ML4NeutronImageSegmentation:contrast}}
The contrast in the sample is a consequence of
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
how well the sample transmits the chosen radiation type. For neutrons you obtain good contrast from materials containing hydrogen or lithium while many metals are more transparent.

\item {} 
the amount of a specific element or material represented in a unit cell, e.g. a pixel (radiograph) or a voxel (tomography).

\end{enumerate}

The objective of many experiments is to quantify the amount of a specific material. This could for example be the amount of water in a porous medium.

Good contrast between different image features is important if you want to segment them to make conclusions about the image content. Therefore, the radiation type should be chosen to provide the best contrast between the features.


\subsubsection{Inhomogeneous contrast}
\label{\detokenize{ML4NeutronImageSegmentation:inhomogeneous-contrast}}
The contrast in the raw radiograph depends much on the beam profile. These variations are easily corrected by normalizing the images by an open beam or flat field image.
\begin{itemize}
\item {} 
\sphinxstylestrong{Biases introduced by scattering} Scattering is the dominant interaction for many materials use in neutron imaging. This means that neutrons that are not passing straight though the sample are scattered and contribute to a background cloud of neutrons that build up a bias of neutron that are also detected and contribute to the

\item {} 
\sphinxstylestrong{Biases from beam hardening} is a problem that is more present in x\sphinxhyphen{}ray imaging and is caused by that fact that the attenuation coefficient depends on the energy of the radiation. Higher energies have lower attenuation coefficient, thus will high energies penetrate the thicker samples than lower energies. This can be seen when a polychromatic beam is used.

\end{itemize}


\subsubsection{Artifacts}
\label{\detokenize{ML4NeutronImageSegmentation:artifacts}}
Many images suffer from outliers caused by stray rays hitting the detector. Typical artefacts in tomography data are
\begin{itemize}
\item {} 
Lines, which are caused by outlier spots that only appear in single projections. These spot appear as lines in the reconstructed images.

\item {} 
Rings are caused by stuck pixels which have the same value in a projections.

\end{itemize}


\section{Introduction to segmentation}
\label{\detokenize{ML4NeutronImageSegmentation:introduction-to-segmentation}}
What is segmentation


\subsection{Basic segmentation: Applying a threshold to an image}
\label{\detokenize{ML4NeutronImageSegmentation:basic-segmentation-applying-a-threshold-to-an-image}}
Start out with a simple image of a cross with added noise
\begin{equation*}
\begin{split} I(x,y) = f(x,y) \end{split}
\end{equation*}
Here, we create a test image with two features embedded in uniform noise; a cross with values in the order of ‘1’ and background with values in the order ‘0’. The figure below shows the image and its histogram. The histogram helps us to see how the graylevels are distributed which helps to decide where to put a threshold that segments the cross from the background.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fig}\PYG{p}{,}\PYG{n}{ax} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{7}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{nx} \PYG{o}{=} \PYG{l+m+mi}{5}\PYG{p}{;} \PYG{n}{ny} \PYG{o}{=} \PYG{l+m+mi}{5}\PYG{p}{;}
\PYG{n}{xx}\PYG{p}{,} \PYG{n}{yy} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{meshgrid}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{n}{nx}\PYG{p}{,} \PYG{n}{nx}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{o}{/}\PYG{n}{nx}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{p}{,} 
                     \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{n}{ny}\PYG{p}{,} \PYG{n}{ny}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{o}{/}\PYG{n}{ny}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{p}{)}
\PYG{n}{cross\PYGZus{}im} \PYG{o}{=}   \PYG{l+m+mf}{1.5}\PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{abs}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{cos}\PYG{p}{(}\PYG{n}{xx}\PYG{o}{*}\PYG{n}{yy}\PYG{p}{)}\PYG{p}{)}\PYG{o}{/}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{abs}\PYG{p}{(}\PYG{n}{xx}\PYG{o}{*}\PYG{n}{yy}\PYG{p}{)}\PYG{o}{+}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{/}\PYG{n}{nx}\PYG{p}{)}\PYG{p}{)} \PYG{o}{+} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{uniform}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.25}\PYG{p}{,} \PYG{l+m+mf}{0.25}\PYG{p}{,} \PYG{n}{size} \PYG{o}{=} \PYG{n}{xx}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\PYG{n}{im}\PYG{o}{=}\PYG{n}{ax}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{cross\PYGZus{}im}\PYG{p}{,} \PYG{n}{cmap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;} 
\PYG{n}{ax}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{o}{.}\PYG{n}{hist}\PYG{p}{(}\PYG{n}{cross\PYGZus{}im}\PYG{o}{.}\PYG{n}{ravel}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}\PYG{n}{bins}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{ML4NeutronImageSegmentation_22_0}.png}


\subsection{Applying a threshold to an image}
\label{\detokenize{ML4NeutronImageSegmentation:applying-a-threshold-to-an-image}}
By examining the image and probability distribution function, we can \sphinxstyleemphasis{deduce} that the underyling model is a whitish phase that makes up the cross and the darkish background

Applying the threshold is a deceptively simple operation
\begin{equation*}
\begin{split} I(x,y) = 
\begin{cases}
1, & f(x,y)\geq0.40 \\
0, & f(x,y)<0.40
\end{cases}\end{split}
\end{equation*}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{threshold} \PYG{o}{=} \PYG{l+m+mf}{0.4}\PYG{p}{;} \PYG{n}{thresh\PYGZus{}img} \PYG{o}{=} \PYG{n}{cross\PYGZus{}im} \PYG{o}{\PYGZgt{}} \PYG{n}{threshold}

\PYG{n}{fig}\PYG{p}{,}\PYG{n}{ax} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{8}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{ax}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{cross\PYGZus{}im}\PYG{p}{,} \PYG{n}{cmap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{extent} \PYG{o}{=} \PYG{p}{[}\PYG{n}{xx}\PYG{o}{.}\PYG{n}{min}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{xx}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{yy}\PYG{o}{.}\PYG{n}{min}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{yy}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{p}{)}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{ax}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{xx}\PYG{p}{[}\PYG{n}{np}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{n}{thresh\PYGZus{}img}\PYG{p}{)}\PYG{p}{]}\PYG{o}{*}\PYG{l+m+mf}{0.9}\PYG{p}{,} \PYG{n}{yy}\PYG{p}{[}\PYG{n}{np}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{n}{thresh\PYGZus{}img}\PYG{p}{)}\PYG{p}{]}\PYG{o}{*}\PYG{l+m+mf}{0.9}\PYG{p}{,}
           \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ks}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{markerfacecolor} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{green}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{alpha} \PYG{o}{=} \PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{n}{label} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Threshold}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{markersize} \PYG{o}{=} \PYG{l+m+mi}{15}\PYG{p}{)}\PYG{p}{;} \PYG{n}{ax}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{n}{fontsize}\PYG{o}{=}\PYG{l+m+mi}{8}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ax}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{o}{.}\PYG{n}{hist}\PYG{p}{(}\PYG{n}{cross\PYGZus{}im}\PYG{o}{.}\PYG{n}{ravel}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}\PYG{n}{bins}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{;} \PYG{n}{ax}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{o}{.}\PYG{n}{axvline}\PYG{p}{(}\PYG{n}{x}\PYG{o}{=}\PYG{n}{threshold}\PYG{p}{,}\PYG{n}{color}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Threshold}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;} \PYG{n}{ax}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{n}{fontsize}\PYG{o}{=}\PYG{l+m+mi}{8}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{ML4NeutronImageSegmentation_26_0}.png}


\section{Noise and SNR}
\label{\detokenize{ML4NeutronImageSegmentation:noise-and-snr}}

\section{Problematic segmentation tasks}
\label{\detokenize{ML4NeutronImageSegmentation:problematic-segmentation-tasks}}
Intro


\section{Segmenation problems in neutron imaging}
\label{\detokenize{ML4NeutronImageSegmentation:segmenation-problems-in-neutron-imaging}}

\chapter{Limited data problem}
\label{\detokenize{ML4NeutronImageSegmentation:limited-data-problem}}

\section{Training data from NI is limited}
\label{\detokenize{ML4NeutronImageSegmentation:training-data-from-ni-is-limited}}

\section{Augmentation}
\label{\detokenize{ML4NeutronImageSegmentation:augmentation}}

\section{Transfer learning}
\label{\detokenize{ML4NeutronImageSegmentation:transfer-learning}}

\chapter{Unsupervised segmentation}
\label{\detokenize{ML4NeutronImageSegmentation:unsupervised-segmentation}}\begin{itemize}
\item {} 
e.g. k\sphinxhyphen{}means

\end{itemize}


\chapter{Supervised segmentation}
\label{\detokenize{ML4NeutronImageSegmentation:supervised-segmentation}}\begin{itemize}
\item {} 
e.g. k\sphinxhyphen{}NN, decision trees

\item {} 
NNs for segmentation

\end{itemize}


\section{Example \sphinxhyphen{} Detecting and correcting unwanted outliers (a.k.a. spots) in neutron images}
\label{\detokenize{ML4NeutronImageSegmentation:example-detecting-and-correcting-unwanted-outliers-a-k-a-spots-in-neutron-images}}

\subsection{Training data}
\label{\detokenize{ML4NeutronImageSegmentation:training-data}}
We have two choices:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Use real data
\begin{itemize}
\item {} 
requires time consuming markup to provide training data

\item {} 
corresponds to real life images

\end{itemize}

\item {} 
Synthesize data
\begin{itemize}
\item {} 
flexible and provides both ‘dirty’ data and ground truth.

\item {} 
model may not behave as real data

\end{itemize}

\end{enumerate}


\subsection{Baseline \sphinxhyphen{} Traditional spot cleaning algorithm}
\label{\detokenize{ML4NeutronImageSegmentation:baseline-traditional-spot-cleaning-algorithm}}
\sphinxincludegraphics{{spotclean_algorithm}.pdf}



\sphinxstylestrong{Parameters}
\begin{itemize}
\item {} 
\sphinxstyleemphasis{N} Width of median filter.

\item {} 
\sphinxstyleemphasis{k} Threshold level for outlier detection.

\end{itemize}


\subsection{The spot cleaning algorithm}
\label{\detokenize{ML4NeutronImageSegmentation:the-spot-cleaning-algorithm}}
The baseline algorithm is here implemented as a python function that we will use when we compare the performance of the CNN algorithm. This is the most trivial algorithm for spot cleaning and there are plenty other algorithms to solve this task.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{spotCleaner}\PYG{p}{(}\PYG{n}{img}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mf}{0.95}\PYG{p}{,} \PYG{n}{wsize}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{)} \PYG{p}{:}
    \PYG{n}{mimg} \PYG{o}{=} \PYG{n}{flt}\PYG{o}{.}\PYG{n}{median}\PYG{p}{(}\PYG{n}{img}\PYG{p}{,}\PYG{n}{size}\PYG{o}{=}\PYG{p}{(}\PYG{n}{wsize}\PYG{p}{,}\PYG{n}{wsize}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{timg} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{abs}\PYG{p}{(}\PYG{n}{img}\PYG{o}{\PYGZhy{}}\PYG{n}{mimg}\PYG{p}{)} \PYG{o}{\PYGZlt{}} \PYG{n}{threshold}
    
    \PYG{n}{cleaned} \PYG{o}{=} \PYG{n}{img} \PYG{o}{*} \PYG{n}{timg} \PYG{o}{+} \PYG{n}{mimg} \PYG{o}{*} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}}\PYG{n}{timg}\PYG{p}{)}
    
    \PYG{k}{return} \PYG{n}{cleaned}
\end{sphinxVerbatim}


\subsection{Build a CNN for spot detection and cleaning}
\label{\detokenize{ML4NeutronImageSegmentation:build-a-cnn-for-spot-detection-and-cleaning}}

\subsection{Performance evaluation}
\label{\detokenize{ML4NeutronImageSegmentation:performance-evaluation}}
Any analysis system must be verified

For this we need to split our data into three categories:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Training data

\item {} 
Test data

\item {} 
Validation data

\end{enumerate}


\subsubsection{Compare results using ROC curve}
\label{\detokenize{ML4NeutronImageSegmentation:compare-results-using-roc-curve}}

\chapter{Final problem: Segmenting root networks in the rhizosphere using convolutional NNs}
\label{\detokenize{ML4NeutronImageSegmentation:final-problem-segmenting-root-networks-in-the-rhizosphere-using-convolutional-nns}}\begin{itemize}
\item {} 
Problem definition

\item {} 
NN model

\item {} 
Loss functions

\item {} 
Training

\item {} 
Results

\end{itemize}


\chapter{Future Machine learning challenges in neutron imaging}
\label{\detokenize{ML4NeutronImageSegmentation:future-machine-learning-challenges-in-neutron-imaging}}






\renewcommand{\indexname}{Index}
\printindex
\end{document}